{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Sources**:\n",
    "\n",
    "https://developers.google.com/machine-learning/glossary\n",
    "\n",
    "ChatGPT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Applications, problems to solve, systems to construct\n",
    "task = {'task' : [\"Information Extraction\", \"Machine Reading System\", \"Image Segmentation\", \"Sentiment Analysis\",\n",
    "                  \"Named Entity Recognition\", \"Question Answering\", \"Object Detection\", \"Speech Recognition\",\n",
    "                  \"Recommendation Systems\", \"Time Series Forecasting\", \"Multiclass classification\",\n",
    "                  \"multilabel learning\", 'binary classification', 'clustering', 'segmentation', 'anomaly detection',\n",
    "                  'multi-class classification', 'regression', 'data augmentation', 'feature engineering', \n",
    "                  'machine translation', 'few-shot learning', 'one-shot learning', 'object classification', 'zero-shot learning',\n",
    "                  'NER', 'time series prediction', 'forecasting', 'prediction', 'text-to-image generation', 'image generation',\n",
    "                  'image recognition', 'meta learning', 'multinomial classification', 'multinomial regression', \n",
    "                  'natural language understanding', 'NLU', 'novelty detection', 'outlier detection', 'document collection',\n",
    "                  'audio transcription', 'sentiment analysis', 'entity linking', 'part-of-speech tagging', 'natural language generation',\n",
    "                  'data annotation', 'semantic segmentation', \n",
    "                    'Image Classification',\n",
    "                    'Text Classification',\n",
    "                    'Document Clustering',\n",
    "                    'Sequence Generation',\n",
    "                    'Topic Modeling',\n",
    "                    'Language Modeling',\n",
    "                    'Speech Synthesis',\n",
    "                    'Keyword Extraction',\n",
    "                    'Text Summarization',\n",
    "                    'Text Generation',\n",
    "                    'Anomaly Detection',\n",
    "                    'Fraud Detection',\n",
    "                    'Customer Segmentation',\n",
    "                    'Image Captioning',\n",
    "                    'Video Classification',\n",
    "                    'Object Tracking',\n",
    "                    'Object Recognition',\n",
    "                    'Sentiment Classification',\n",
    "                    'Emotion Recognition',\n",
    "                    'Entity Sentiment Analysis',\n",
    "                    'Relation Extraction',\n",
    "                    'Intent Recognition',\n",
    "                    'Dialogue System',\n",
    "                    'Knowledge Graph Construction',\n",
    "                    'Graph Embedding',\n",
    "                    'Graph Classification',\n",
    "                    'Link Prediction',\n",
    "                    'Network Intrusion Detection',\n",
    "                    'Image Super-Resolution',\n",
    "                    'Instance Segmentation',\n",
    "                    'Text-to-Speech Synthesis',\n",
    "                    'Machine Translation Evaluation',\n",
    "                    'Zero-Shot Translation',\n",
    "                    'Text-to-Text Transfer',\n",
    "                    'Text-to-SQL Generation',\n",
    "                    'Image Style Transfer',\n",
    "                    'Voice Conversion',\n",
    "                    'Text Entailment',\n",
    "                    'Speech Emotion Recognition',\n",
    "                    'Music Recommendation',\n",
    "                    'Biomedical Image Analysis',\n",
    "                    'Gesture Recognition',\n",
    "                    'Adversarial Attack',\n",
    "                    'Image Restoration',\n",
    "                    'Document Similarity',\n",
    "                    'Machine Comprehension',\n",
    "                    'Cross-lingual Information Retrieval',\n",
    "                    'Spatial-Temporal Prediction',\n",
    "                    'Speech Enhancement',\n",
    "                    'Text-to-Code Generation',\n",
    "                    'Content-based Image Retrieval',\n",
    "                    'Video Captioning',\n",
    "                    'Emotion Analysis',\n",
    "                    'Dialogue Generation',\n",
    "                    'Event Detection',\n",
    "                    'Face Recognition',\n",
    "                    'Graph Clustering',\n",
    "                    'Named Entity Disambiguation',\n",
    "                    'Intent Classification',\n",
    "                    'Text Style Transfer',\n",
    "                    'Reinforcement Learning',\n",
    "                    'Automatic Speech Recognition',\n",
    "                    'Semantic Role Labeling',\n",
    "                    'Visual Question Answering',\n",
    "                    'Cross-modal Retrieval',\n",
    "                    'Domain Adaptation',\n",
    "                    'Sentiment Transfer',\n",
    "                    'Text Paraphrasing',\n",
    "                    'Relation Classification',\n",
    "                    'Visual Relationship Detection',\n",
    "                    'Video Summarization',\n",
    "                    'Word Sense Disambiguation',\n",
    "                    'Image Inpainting',\n",
    "                    'Knowledge Graph Completion',\n",
    "                    'Graph Generation',\n",
    "                    'Music Generation',\n",
    "                    'Visual Saliency Prediction',\n",
    "                    'Document Translation',\n",
    "                    'Entity Linking',\n",
    "                    'Code Generation',\n",
    "                    'Object Pose Estimation',\n",
    "                    'Human Activity Recognition',\n",
    "                    'Video Object Segmentation',\n",
    "                    'Sentiment Transfer',\n",
    "                    'Opinion Mining',\n",
    "                    'Event Extraction',\n",
    "                    'Visual Localization',\n",
    "                    'Image-to-Text Generation',\n",
    "                    'Cross-lingual Document Classification',\n",
    "                    'Text-to-Image Translation',\n",
    "                    'Speech Segmentation',\n",
    "                    'Neural Style Transfer',\n",
    "                    'Document Summarization',\n",
    "                    'Pattern Recognition',\n",
    "                    'Malware Detection',\n",
    "                    'Image-to-Image Translation',\n",
    "                    'Video Super-Resolution',\n",
    "                    'Activity Prediction',\n",
    "                    'Speech Diarization',\n",
    "                    'Topological Data Analysis',\n",
    "                  'robotics navigation', '3D reconstruction', 'stereo matching',\n",
    "                  'medical image segmentation', 'interior sensing'\n",
    "\n",
    "                 ]\n",
    " \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "}\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Methods , models, systems to use, or tools, components of a system, frameworks.\n",
    "# E.g. language model, CORENLP, POS parser, kernel method, etc.\n",
    "method = {'method' : ['dimensionality reduction', 'language model', 'CORENLP', 'POS parser', 'kernel method',\n",
    "                      'A/B testing', 'active learning', 'reinforcement learning', 'neural network', 'transformer', \n",
    "                      'decision tree', 'bagging', 'batch normalization', 'regularization', 'bayesian neural network',\n",
    "                      'bayesian optimization', 'BERT', 'RoBERTa', 'ALBERT', 'encoder', 'decoder',\n",
    "                      'autoencoder', 'stacked autoencoder', 'AE', 'SAE', 'bidirectional language model',\n",
    "                      'boosting', 'causal language model', 'centroid-based clustering', 'k-means', 'hierarchical clustering',\n",
    "                      'pairwise clustering', 'SOM', 'self-organizing map', 'classification model', 'recommender system',\n",
    "                      'collaborative filtering', 'convolutional filter', 'convolutional neural network', 'CNN', 'RNN', 'LSTM',\n",
    "                      'convolutional layer', 'pooling layer', 'convolutional layers', 'pooling layers', 'dense layer', 'dense layers',\n",
    "                      'dropout layer', 'dropout layers', 'dense layer', 'dense layers', 'cross-validation', 'CV', 'decision forest',\n",
    "                      'deep neural network', 'feed-forward neural network', 'deep model', 'denoising', 'discriminative model',\n",
    "                      'feature learning', 'kernel regression', 'OLS regression', 'Ridge regression', 'LASSO regression',\n",
    "                      'downsampling', 'dropout regularization', 'early stopping', 'distance function','embedding layer', 'embedding',\n",
    "                      'vectorization', 'tokenization', 'embedding vector', 'empirical risk minimization', 'feature extraction',\n",
    "                      'fine tuning', 'generative adversarial network', 'GAN', 'least squares regression', 'logistic regression',\n",
    "                      'generator', 'discriminator', 'generative pre-trained transformer', 'GPT', 'DALL-E', 'ImageGPT', 'ChatGPT', \n",
    "                      'gradient boosting', 'gradient descent', 'gradient ascent', 'active learning', 'imputation', 'information gain', \n",
    "                      'k-median', 'LaMDA', 'large language model', 'long short-term memory', 'masked language model', \n",
    "                      'stochastic gradient descent', 'multi-class logistic regression', 'multi-head self-attention', \n",
    "                      'Neural Architecture Search', 'N-gram', 'normalization', 'novelty filter', 'one-hot encoding', \n",
    "                      'perceptron', 'pipelining', 'pooling', 'post-processing', 'pre-processing', 'probabilistic regression model',\n",
    "                      'Q-learning', 'bucketing', 'random forest', 'recommendation system', 'scaling', 'whitening', 'whiten', 'scale',\n",
    "                      'self-attention', 'self-supervised learning', 'self-training', 'semi-supervised learning', 'spatial pooling',\n",
    "                      'subsampling', 'uplift modeling', 'variational autoencoder', 'VAE', \n",
    "                          'Generative Pre-trained Transformer 2',\n",
    "                    'Graph Neural Network',\n",
    "                    'Inception Network',\n",
    "                    'K-Nearest Neighbors',\n",
    "                    'Latent Dirichlet Allocation',\n",
    "                    'Memory Network',\n",
    "                    'Metric Learning',\n",
    "                    'Ordinal Regression',\n",
    "                    'Principal Component Analysis',\n",
    "                    'Quantization',\n",
    "                    'Radial Basis Function Network',\n",
    "                    'Recurrent Neural Network',\n",
    "                    'Self-Supervised Learning',\n",
    "                    'Sequence-to-Sequence',\n",
    "                    'Siamese Network',\n",
    "                    'Sparse Coding',\n",
    "                    'Structured Prediction',\n",
    "                    'Temporal Convolutional Network',\n",
    "                    'Temporal Difference Learning',\n",
    "                    'Tensor Decomposition',\n",
    "                    'Transfer Learning',\n",
    "                    'Variational Inference',\n",
    "                    'VGG Network',\n",
    "                    'Word Embedding',\n",
    "                    'XGBoost',\n",
    "                    'Zero-Shot Learning',\n",
    "                    'Attention Mechanism',\n",
    "                    'Capsule Network',\n",
    "                    'Deep Q-Network',\n",
    "                    'Ensemble Learning',\n",
    "                    'Federated Learning',\n",
    "                    'Gated Recurrent Unit',\n",
    "                    'Generative Model',\n",
    "                    'Knowledge Graph',\n",
    "                    'Neural Architecture Compression',\n",
    "                    'Ordinal Classification',\n",
    "                    'Reinforcement Learning',\n",
    "                    'Residual Network',\n",
    "                    'Semi-Supervised Learning',\n",
    "                    'Spatial Transformer Network',\n",
    "                    'Unsupervised Learning',\n",
    "                    'Variational Autoencoder',\n",
    "                    'Word2Vec',\n",
    "                    'Yolo',\n",
    "                    'Zero-Shot Text Classification',\n",
    "                    'AutoML',\n",
    "                    'Capsule Routing',\n",
    "                    'Deep Reinforcement Learning',\n",
    "                    'Ensemble Method',\n",
    "                    'Evolutionary Algorithm',\n",
    "                    'Graph Convolutional Network',\n",
    "                    'Hierarchical Attention Network',\n",
    "                      'deep model', 'deep models', 'segmentation', 'gaussian mixture model', 'gaussian mixture models', 'GMM',\n",
    "                      'transfer learning', 'semantic segmentation', 'context extraction', 'CNNs', 'RNNs', 'transformers', 'autoencoder', 'AE',\n",
    "                      'neural networks', 'deep neural networks'\n",
    "                      \n",
    "                      \n",
    "                      \n",
    "                      \n",
    "                      \n",
    "                      \n",
    "                      \n",
    "                     ]\n",
    "                      }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluation Metric: Metrics, measures, or entities that can express quality of a system/method.\n",
    "# E.g. F1, BLEU, Precision, Recall, ROC curve, mean reciprocal rank, mean-squared error, robustness, time complexity\n",
    "\n",
    "eval_metric = {'evaluation metric' : ['F1', 'BLEU', 'Precision', 'Recall', 'ROC curve', 'mean reciprocal rank',\n",
    "                                      'mean-squared error', 'robustness', 'time complexity', 'mean absolute error',\n",
    "                                      'MSE', 'MAE', 'MAPE', 'mean absolute percentage error', 'MPE', 'mean percentage error', \n",
    "                                      'entropy', 'accuracy', 'AUC', 'area under the ROC curve', 'loss', 'auxiliary loss', 'average precision',\n",
    "                                      'variance', 'standard deviation', 'confusion matrix', 'loss function', 'cost', 'cross-entropy',\n",
    "                                      'entropy', 'Kullback-Leibler divergence', 'gini impurity', 'mutual information', 'false negative rate',\n",
    "                                      'false positive rate', 'FNR', 'FPR', 'training loss', 'validation loss', 'information gain', 'gini index',\n",
    "                                      'k-fold cross-validation', 'Euclidean distance', 'Manhattan distance', 'log loss', 'perplexity',\n",
    "                                      'Root Mean Squared Error', 'RMSE', 'R-squared', 'squared loss', 'true positive rate', 'TPR', 'true negative rate',\n",
    "                                      'TNR', \n",
    "                                      'Precision-Recall Curve',\n",
    "                                    'Jaccard Index',\n",
    "                                    'Hamming Loss',\n",
    "                                    'Cohen\\'s Kappa',\n",
    "                                    'Matthews Correlation Coefficient',\n",
    "                                    'Fowlkes-Mallows Index',\n",
    "                                    'Adjusted Rand Index',\n",
    "                                    'Normalized Mutual Information',\n",
    "                                    'Explained Variance',\n",
    "                                    'Silhouette Coefficient',\n",
    "                                    'Brier Score',\n",
    "                                    'Hubness',\n",
    "                                    'Kolmogorov-Smirnov statistic',\n",
    "                                    'Median Absolute Deviation',\n",
    "                                    'Hinge Loss',\n",
    "                                    'Jensen-Shannon Divergence',\n",
    "                                    'Bhattacharyya Distance',\n",
    "                                    'Earth Mover\\'s Distance',\n",
    "                                    'Precision at K',\n",
    "                                    'Recall at K',\n",
    "                                    'Mean Average Precision',\n",
    "                                    'Balanced Accuracy',\n",
    "                                    'C-index',\n",
    "                                    'Goodness of Fit',\n",
    "                                    'Out-of-Bag Error',\n",
    "                                    'Outlier Score',\n",
    "                                    'Ranking Loss',\n",
    "                                    'Relative Absolute Error',\n",
    "                                    'Relative Squared Error',\n",
    "                                    'Rouge Score',\n",
    "                                    'Kendall Rank Correlation Coefficient',\n",
    "                                    'Spearman Rank Correlation Coefficient',\n",
    "                                    'Tau Rank Correlation Coefficient',\n",
    "                                    'Hamming Distance',\n",
    "                                    'Kolmogorov-Smirnov Test',\n",
    "                                    'Mutual Information Score',\n",
    "                                    'Precision at Recall',\n",
    "                                    'Recall at Precision',\n",
    "                                    'Inverse Document Frequency',\n",
    "                                    'Lift',\n",
    "                                    'Logistic Loss',\n",
    "                                    'Permutation Importance',\n",
    "                                    'Probabilistic Loss',\n",
    "                                    'Scatter Index',\n",
    "                                    'Top-N Accuracy',\n",
    "                                    'Unweighted Average Recall',\n",
    "                                    'Zero-One Loss', \n",
    "                                      'speed', 'robustness', 'usability', 'fairness'\n",
    "                                      \n",
    "                                      \n",
    "                                      \n",
    "                      \n",
    "                      \n",
    "                      \n",
    "                      \n",
    "                     ]\n",
    "                      }\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Material: Data, datasets, resources, Corpus, Knowledge base.\n",
    "# E.g. image data, speech data, stereo images, bilingual dictionary, paraphrased questions, CoNLL, Panntreebank, WordNet, Wikipedia,\n",
    "\n",
    "material = {'material' : ['image data', \n",
    "                            'speech data',\n",
    "                            'text data',\n",
    "                            'tabular data',\n",
    "                            'stereo images',\n",
    "                            'bilingual dictionary',\n",
    "                            'paraphrased questions',\n",
    "                            'CoNLL',\n",
    "                            'Panntreebank',\n",
    "                            'WordNet',\n",
    "                            'Wikipedia',\n",
    "                            'temporal data',\n",
    "                            'image dataset',\n",
    "                            'speech dataset',\n",
    "                            'text dataset',\n",
    "                            'tabular dataset',\n",
    "                            'stereoscopic images',\n",
    "                            'multilingual dictionary',\n",
    "                            'rewritten questions',\n",
    "                            'CoNLL format',\n",
    "                            'Penn Treebank',\n",
    "                            'lexical database',\n",
    "                            'Wikimedia',\n",
    "                            'time-series data',\n",
    "                            'visual data',\n",
    "                            'audio data',\n",
    "                            'natural language corpus',\n",
    "                            'relational data',\n",
    "                            'depth maps',\n",
    "                            'translation memory',\n",
    "                            'rewritten queries',\n",
    "                            'Universal Dependencies',\n",
    "                            'ontology',\n",
    "                            'web content',\n",
    "                            'sequential data',\n",
    "                            'satellite imagery',\n",
    "                            'multilingual corpus',\n",
    "                            'visual dataset',\n",
    "                            'acoustic data',\n",
    "                            'corpus of text',\n",
    "                            'structured data',\n",
    "                            '3D images',\n",
    "                            'translation dictionary',\n",
    "                            'reformulated questions',\n",
    "                            'ConceptNet',\n",
    "                            'Wiktionary',\n",
    "                            'historical data',\n",
    "                            'medical images',\n",
    "                            'audio recordings',\n",
    "                            'document text',\n",
    "                            'spreadsheet data',\n",
    "                            'depth perception',\n",
    "                            'multilingual glossary',\n",
    "                            'rewritten queries',\n",
    "                            'JSON format',\n",
    "                            'Dependency Bank',\n",
    "                            'Roget\\'s Thesaurus',\n",
    "                            'online encyclopedia',\n",
    "                            'spatial data',\n",
    "                            'photographic images',\n",
    "                            'voice recordings',\n",
    "                            'linguistic data',\n",
    "                            'relational database',\n",
    "                            'stereoscopic vision',\n",
    "                            'multilingual thesaurus',\n",
    "                            'paraphrased statements',\n",
    "                            'LDC format',\n",
    "                            'GUM corpus',\n",
    "                            'knowledge graph',\n",
    "                            'temporal sequences',\n",
    "                            'visual representation',\n",
    "                            'speech corpus',\n",
    "                            'textual dataset',\n",
    "                            'structured information',\n",
    "                            'disparity maps',\n",
    "                            'translation database',\n",
    "                            'alternative queries',\n",
    "                            'UD treebank',\n",
    "                            'knowledge base',\n",
    "                            'web pages',\n",
    "                            'temporal records',\n",
    "                            'satellite photos',\n",
    "                            'multilingual text collection',\n",
    "                            'visual collection',\n",
    "                            'environmental sounds',\n",
    "                            'textual corpus',\n",
    "                            'structured records',\n",
    "                            '3D reconstructions',\n",
    "                            'translation memory bank',\n",
    "                            'modified queries',\n",
    "                            'ConceptNet knowledge graph',\n",
    "                            'linguistic dictionary',\n",
    "                            'historical records',\n",
    "                            'video data',\n",
    "                            'audio transcripts',\n",
    "                            'textual resources',\n",
    "                            'multivariate data'\n",
    "                      \n",
    "                      \n",
    "                      \n",
    "                      \n",
    "                     ]\n",
    "                      }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generic: General terms or pronouns that may refer to a entity but are not themselves informative, often used as connection words.\n",
    "# E.g model, approach, prior knowledge, them, it\n",
    "\n",
    "generic = {'generic' : ['model', 'approach', 'prior knowledge', 'them', 'it', 'action', 'agent', 'function', 'algorithm',\n",
    "                        'parameter', 'baseline', 'batch', 'candidate', 'category', 'data', 'dataset', 'datapoint', 'data set',\n",
    "                        'data point', 'threshold', 'condition', 'configuration', 'optimizer', 'learning rate', 'hyperparameter', \n",
    "                        'bias', 'feature', 'convergence', 'rate', 'set', 'subset', 'depth', 'device', 'dimension', 'dimensions',\n",
    "                        'environment', 'epoch', 'estimator', 'example', 'label', 'experiment', 'problem', 'analysis', 'study',\n",
    "                        'learning', 'iteration', 'instance', 'condition', 'item', 'items', 'input', 'output', 'parity', 'prior belief',\n",
    "                        'class', 'modeling', 'approach', 'prior information',\n",
    "                        'entities',\n",
    "                        'object',\n",
    "                        'action sequence',\n",
    "                        'intelligent agent',\n",
    "                        'functionality',\n",
    "                        'optimization algorithm',\n",
    "                        'model parameter',\n",
    "                        'performance baseline',\n",
    "                        'data batch',\n",
    "                        'candidate solution',\n",
    "                        'classification category',\n",
    "                        'input data',\n",
    "                        'training dataset',\n",
    "                        'data instance',\n",
    "                        'dataset',\n",
    "                        'data sample',\n",
    "                        'classification threshold',\n",
    "                        'conditional statement',\n",
    "                        'system configuration',\n",
    "                        'optimization technique',\n",
    "                        'learning rate parameter',\n",
    "                        'tuning parameter',\n",
    "                        'system bias',\n",
    "                        'feature vector',\n",
    "                        'convergence criterion',\n",
    "                        'learning speed',\n",
    "                        'data collection',\n",
    "                        'data subset',\n",
    "                        'tree depth',\n",
    "                        'computing device',\n",
    "                        'feature dimension',\n",
    "                        'data dimensions',\n",
    "                        'environmental setup',\n",
    "                        'training epoch',\n",
    "                        'predictive model',\n",
    "                        'example instance',\n",
    "                        'class label',\n",
    "                        'experimental trial',\n",
    "                        'problem statement',\n",
    "                        'data analysis',\n",
    "                        'research study',\n",
    "                        'machine learning',\n",
    "                        'iterative process',\n",
    "                        'data item',\n",
    "                        'collection condition',\n",
    "                        'input item',\n",
    "                        'output item',\n",
    "                        'parity check',\n",
    "                        'prior belief',\n",
    "                        'class category',\n",
    "                        'tool', 'idea', 'network', 'classifier'\n",
    "                        \n",
    "                        \n",
    "                        \n",
    "                      \n",
    "                      \n",
    "                      \n",
    "                      \n",
    "                     ]\n",
    "                      }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "dictionary = {**task, **method, **eval_metric, **material, **generic}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "152\n",
      "198\n",
      "105\n",
      "97\n",
      "112\n"
     ]
    }
   ],
   "source": [
    "print(len(dictionary['task'])) \n",
    "print(len(dictionary['method'])) \n",
    "print(len(dictionary['evaluation metric'])) \n",
    "print(len(dictionary['material'])) \n",
    "print(len(dictionary['generic'])) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open('dict_out.json', \"w\") as json_file:\n",
    "    json.dump(dictionary, json_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
